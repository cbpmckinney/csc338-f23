{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "def SoftMax(values):\n",
    "    answers = [0]*len(values)\n",
    "    denom = 0\n",
    "    for i in range(len(values)):\n",
    "        denom += math.exp(values[i])\n",
    "    for i in range(len(values)):\n",
    "        answers[i] = math.exp(values[i])/denom\n",
    "    return answers\n",
    "\n",
    "\n",
    "def OneHot(label):\n",
    "    ans = [0]*10\n",
    "    ans[label] = 1\n",
    "    return ans\n",
    "\n",
    "\n",
    "class neuralnet:\n",
    "\n",
    "    def __init__(self, numinputs, numoutputs, errorfunc=\"MSE\"):\n",
    "\n",
    "        self.numinputs = numinputs\n",
    "        self.numoutputs = numoutputs\n",
    "        self.errorfunc = errorfunc\n",
    "        \n",
    "        self.biases = np.random.default_rng().random(self.numoutputs)\n",
    "        self.weights = np.random.default_rng().random((self.numoutputs, self.numinputs))\n",
    "\n",
    "    def evaluate(self, inputs):\n",
    "            try:\n",
    "                output = self.weights @ inputs + self.biases\n",
    "                return output\n",
    "            except:\n",
    "                print(\"Dimension mismatch!\")\n",
    "\n",
    "    def computeerror(self, outputs, trueoutputs):\n",
    "         if self.errorfunc == \"MSE\":\n",
    "            pass # You need to put the MSE stuff here\n",
    "         \n",
    "\n",
    "         if self.errorfunc == \"CrossEntropy\":\n",
    "            sum = 0\n",
    "            for i in range(0, len(outputs)):\n",
    "                sum += -trueoutputs[i]*math.log2(outputs[i])\n",
    "            return sum\n",
    "\n",
    "\n",
    "    def computegradient(self, inputs, labels):\n",
    "\n",
    "        wparts = np.zeros((self.numoutputs, self.numinputs))\n",
    "        bparts = np.zeros(self.numoutputs)\n",
    "\n",
    "        if self.errorfunc == \"MSE\":\n",
    "            \n",
    "            # You need to put stuff here\n",
    "\n",
    "\n",
    "            return (wparts, bparts)\n",
    "\n",
    "\n",
    "        if self.errorfunc == \"CrossEntropy\":\n",
    "            ys = self.weights @ inputs + self.biases\n",
    "            softdenom = 0\n",
    "            for i in range(len(ys)):\n",
    "                softdenom += math.exp(ys[i])\n",
    "            \n",
    "            for i in range(self.numoutputs):\n",
    "                bparts[i] = - labels[i] * (softdenom - math.exp(ys[i])) / (softdenom * math.log(2))\n",
    "                for j in range(0, self.numinputs):\n",
    "                    wparts[i,j] = inputs[j] * bparts[i]\n",
    "\n",
    "            return (wparts, bparts)\n",
    "\n",
    "       \n",
    "\n",
    "        \n",
    "    \n",
    "    def updateweights(self, wparts, bparts, eta):\n",
    "\n",
    "        # This doesn't need to be changed, since all it takes in are\n",
    "        # the partial derivatives computed elsewhere\n",
    "\n",
    "        self.weights -= eta*wparts\n",
    "        self.biases -= eta*bparts\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "              \n",
    "\n",
    "         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Define two versions of our neural net\n",
    "\n",
    "MyNeuralNet1 = neuralnet(784,10,\"CrossEntropy\")\n",
    "MyNeuralNet2 = neuralnet(784,10,\"MSE\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell once, to train each network over 10 epochs.  Then run the next cell to compute the errors.\n",
    "# THEN: Re-run this cell and the next cell to see how the error decreases for each NN.\n",
    "\n",
    "# Train Neural Net 1, 1000 images, over 10 epochs\n",
    "\n",
    "for j in range(10):\n",
    "    for i in range(1000):\n",
    "        image = (train_images[i].astype(float)/255).flatten()\n",
    "        label = OneHot(train_labels[i])\n",
    "        (wparts, bparts) = MyNeuralNet1.computegradient(image, label)\n",
    "        MyNeuralNet1.updateweights(wparts, bparts, 0.01)\n",
    "\n",
    "\n",
    "# Train Neural Net 2, 1000 images, over 10 epochs\n",
    "\n",
    "for j in range(10):\n",
    "    for i in range(1000):\n",
    "        image = (train_images[i].astype(float)/255).flatten()\n",
    "        label = OneHot(train_labels[i])\n",
    "        (wparts, bparts) = MyNeuralNet2.computegradient(image, label)\n",
    "        MyNeuralNet2.updateweights(wparts, bparts, 0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1010874112891518\n"
     ]
    }
   ],
   "source": [
    "cumulativeerror1 = 0\n",
    "cumulativeerror2 = 0\n",
    "\n",
    "for i in range(1000):\n",
    "    test1 = (test_images[i].astype(float)/255).flatten()\n",
    "    label1 = OneHot(test_labels[i])\n",
    "    out1 = SoftMax(MyNeuralNet1.evaluate(test1))\n",
    "    cumulativeerror1 += MyNeuralNet1.computeerror(out1, label1)\n",
    "\n",
    "for i in range(1000):\n",
    "    test1 = (test_images[i].astype(float)/255).flatten()\n",
    "    label1 = OneHot(test_labels[i])\n",
    "    #out1 = SoftMax(MyNeuralNet1.evaluate(test1)) Change this\n",
    "    cumulativeerror1 += MyNeuralNet2.computeerror(out1, label1)\n",
    "\n",
    "print(cumulativeerror1/1000)\n",
    "print(cumulativeerror2/1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this cell, choose a (random) test image.  Display it and print its label.\n",
    "\n",
    "randnum = random.randrange(10000)\n",
    "randimage = test_images[randnum]\n",
    "randlabel = test_labels[randnum]\n",
    "\n",
    "plt.imshow(randimage, interpolation=\"nearest\",cmap=\"gray\")\n",
    "\n",
    "print(randlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, evaluate both neural networks on the randomly chosen image.\n",
    "# Softmax the result of the MSE version so that the two sets of probabilities are \n",
    "# comparable to each other.  Does one NN do better than the other?  Majorly?  Minorly?\n",
    "# About the same?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
