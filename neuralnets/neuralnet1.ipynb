{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 09:23:36.530062: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-03 09:23:36.554166: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-03 09:23:36.647754: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-03 09:23:36.648214: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-03 09:23:37.483311: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbe0lEQVR4nO3df2xV9f3H8dflR6+I7e1KbW8rPyygsIlgxqDrVMRRKd1G5McWdS7BzWhwrRGYuNRM0W2uDqczbEz5Y4GxCSjJgEEWNi22ZLNgQBgxbg0l3VpGWyZb7y2FFmw/3z+I98uVFjyXe/u+vTwfySeh955378fjtU9vezn1OeecAADoZ4OsNwAAuDIRIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYGKI9QY+qaenR8eOHVN6erp8Pp/1dgAAHjnn1N7ervz8fA0a1PfrnKQL0LFjxzRq1CjrbQAALlNTU5NGjhzZ5/1J9y249PR06y0AAOLgUl/PExag1atX6/rrr9dVV12lwsJCvfvuu59qjm+7AUBquNTX84QE6PXXX9eyZcu0YsUKvffee5oyZYpKSkp0/PjxRDwcAGAgcgkwffp0V1ZWFvm4u7vb5efnu8rKykvOhkIhJ4nFYrFYA3yFQqGLfr2P+yugM2fOaP/+/SouLo7cNmjQIBUXF6u2tvaC47u6uhQOh6MWACD1xT1AH374obq7u5Wbmxt1e25urlpaWi44vrKyUoFAILJ4BxwAXBnM3wVXUVGhUCgUWU1NTdZbAgD0g7j/PaDs7GwNHjxYra2tUbe3trYqGAxecLzf75ff74/3NgAASS7ur4DS0tI0depUVVVVRW7r6elRVVWVioqK4v1wAIABKiFXQli2bJkWLVqkL3zhC5o+fbpefvlldXR06Nvf/nYiHg4AMAAlJED33HOP/vOf/+jpp59WS0uLbrnlFu3cufOCNyYAAK5cPuecs97E+cLhsAKBgPU2AACXKRQKKSMjo8/7zd8FBwC4MhEgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmhlhvAEgmgwcP9jwTCAQSsJP4KC8vj2nu6quv9jwzYcIEzzNlZWWeZ372s595nrnvvvs8z0hSZ2en55nnn3/e88yzzz7reSYV8AoIAGCCAAEATMQ9QM8884x8Pl/UmjhxYrwfBgAwwCXkZ0A33XST3nrrrf9/kCH8qAkAEC0hZRgyZIiCwWAiPjUAIEUk5GdAhw8fVn5+vsaOHav7779fjY2NfR7b1dWlcDgctQAAqS/uASosLNS6deu0c+dOvfLKK2poaNDtt9+u9vb2Xo+vrKxUIBCIrFGjRsV7SwCAJBT3AJWWluob3/iGJk+erJKSEv3xj39UW1ub3njjjV6Pr6ioUCgUiqympqZ4bwkAkIQS/u6AzMxM3Xjjjaqvr+/1fr/fL7/fn+htAACSTML/HtDJkyd15MgR5eXlJfqhAAADSNwD9Pjjj6umpkb//Oc/9c4772j+/PkaPHhwzJfCAACkprh/C+7o0aO67777dOLECV177bW67bbbtGfPHl177bXxfigAwAAW9wBt2rQp3p8SSWr06NGeZ9LS0jzPfOlLX/I8c9ttt3mekc79zNKrhQsXxvRYqebo0aOeZ1atWuV5Zv78+Z5n+noX7qX87W9/8zxTU1MT02NdibgWHADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgwuecc9abOF84HFYgELDexhXllltuiWlu165dnmf4dzsw9PT0eJ75zne+43nm5MmTnmdi0dzcHNPc//73P88zdXV1MT1WKgqFQsrIyOjzfl4BAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwMQQ6w3AXmNjY0xzJ06c8DzD1bDP2bt3r+eZtrY2zzN33nmn5xlJOnPmjOeZ3/72tzE9Fq5cvAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwMVLov//9b0xzy5cv9zzzta99zfPMgQMHPM+sWrXK80ysDh486Hnmrrvu8jzT0dHheeamm27yPCNJjz32WExzgBe8AgIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATPicc856E+cLh8MKBALW20CCZGRkeJ5pb2/3PLNmzRrPM5L04IMPep751re+5Xlm48aNnmeAgSYUCl30v3leAQEATBAgAIAJzwHavXu35s6dq/z8fPl8Pm3dujXqfuecnn76aeXl5WnYsGEqLi7W4cOH47VfAECK8Bygjo4OTZkyRatXr+71/pUrV2rVqlV69dVXtXfvXg0fPlwlJSXq7Oy87M0CAFKH59+IWlpaqtLS0l7vc87p5Zdf1g9+8APdfffdkqT169crNzdXW7du1b333nt5uwUApIy4/gyooaFBLS0tKi4ujtwWCARUWFio2traXme6uroUDoejFgAg9cU1QC0tLZKk3NzcqNtzc3Mj931SZWWlAoFAZI0aNSqeWwIAJCnzd8FVVFQoFApFVlNTk/WWAAD9IK4BCgaDkqTW1tao21tbWyP3fZLf71dGRkbUAgCkvrgGqKCgQMFgUFVVVZHbwuGw9u7dq6Kiong+FABggPP8LriTJ0+qvr4+8nFDQ4MOHjyorKwsjR49WkuWLNGPf/xj3XDDDSooKNBTTz2l/Px8zZs3L577BgAMcJ4DtG/fPt15552Rj5ctWyZJWrRokdatW6cnnnhCHR0devjhh9XW1qbbbrtNO3fu1FVXXRW/XQMABjwuRoqU9MILL8Q09/H/UHlRU1Pjeeb8v6rwafX09HieASxxMVIAQFIiQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACa6GjZQ0fPjwmOa2b9/ueeaOO+7wPFNaWup55s9//rPnGcASV8MGACQlAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEFyMFzjNu3DjPM++9957nmba2Ns8zb7/9tueZffv2eZ6RpNWrV3ueSbIvJUgCXIwUAJCUCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATXIwUuEzz58/3PLN27VrPM+np6Z5nYvXkk096nlm/fr3nmebmZs8zGDi4GCkAICkRIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GClgYNKkSZ5nXnrpJc8zs2bN8jwTqzVr1nieee655zzP/Pvf//Y8AxtcjBQAkJQIEADAhOcA7d69W3PnzlV+fr58Pp+2bt0adf8DDzwgn88XtebMmROv/QIAUoTnAHV0dGjKlClavXp1n8fMmTNHzc3NkbVx48bL2iQAIPUM8TpQWlqq0tLSix7j9/sVDAZj3hQAIPUl5GdA1dXVysnJ0YQJE/TII4/oxIkTfR7b1dWlcDgctQAAqS/uAZozZ47Wr1+vqqoq/fSnP1VNTY1KS0vV3d3d6/GVlZUKBAKRNWrUqHhvCQCQhDx/C+5S7r333sifb775Zk2ePFnjxo1TdXV1r38noaKiQsuWLYt8HA6HiRAAXAES/jbssWPHKjs7W/X19b3e7/f7lZGREbUAAKkv4QE6evSoTpw4oby8vEQ/FABgAPH8LbiTJ09GvZppaGjQwYMHlZWVpaysLD377LNauHChgsGgjhw5oieeeELjx49XSUlJXDcOABjYPAdo3759uvPOOyMff/zzm0WLFumVV17RoUOH9Jvf/EZtbW3Kz8/X7Nmz9aMf/Uh+vz9+uwYADHhcjBQYIDIzMz3PzJ07N6bHWrt2recZn8/neWbXrl2eZ+666y7PM7DBxUgBAEmJAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgaNoALdHV1eZ4ZMsTzb3fRRx995Hkmlt8tVl1d7XkGl4+rYQMAkhIBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYML71QMBXLbJkyd7nvn617/ueWbatGmeZ6TYLiwaiw8++MDzzO7duxOwE1jgFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKLkQLnmTBhgueZ8vJyzzMLFizwPBMMBj3P9Kfu7m7PM83NzZ5nenp6PM8gOfEKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwcVIkfRiuQjnfffdF9NjxXJh0euvvz6mx0pm+/bt8zzz3HPPeZ75wx/+4HkGqYNXQAAAEwQIAGDCU4AqKys1bdo0paenKycnR/PmzVNdXV3UMZ2dnSorK9OIESN0zTXXaOHChWptbY3rpgEAA5+nANXU1KisrEx79uzRm2++qbNnz2r27Nnq6OiIHLN06VJt375dmzdvVk1NjY4dOxbTL98CAKQ2T29C2LlzZ9TH69atU05Ojvbv368ZM2YoFArp17/+tTZs2KAvf/nLkqS1a9fqs5/9rPbs2aMvfvGL8ds5AGBAu6yfAYVCIUlSVlaWJGn//v06e/asiouLI8dMnDhRo0ePVm1tba+fo6urS+FwOGoBAFJfzAHq6enRkiVLdOutt2rSpEmSpJaWFqWlpSkzMzPq2NzcXLW0tPT6eSorKxUIBCJr1KhRsW4JADCAxBygsrIyvf/++9q0adNlbaCiokKhUCiympqaLuvzAQAGhpj+Imp5ebl27Nih3bt3a+TIkZHbg8Ggzpw5o7a2tqhXQa2trX3+ZUK/3y+/3x/LNgAAA5inV0DOOZWXl2vLli3atWuXCgoKou6fOnWqhg4dqqqqqshtdXV1amxsVFFRUXx2DABICZ5eAZWVlWnDhg3atm2b0tPTIz/XCQQCGjZsmAKBgB588EEtW7ZMWVlZysjI0KOPPqqioiLeAQcAiOIpQK+88ookaebMmVG3r127Vg888IAk6ec//7kGDRqkhQsXqqurSyUlJfrVr34Vl80CAFKHzznnrDdxvnA4rEAgYL0NfAq5ubmeZz73uc95nvnlL3/peWbixImeZ5Ld3r17Pc+88MILMT3Wtm3bPM/09PTE9FhIXaFQSBkZGX3ez7XgAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYCKm34iK5JWVleV5Zs2aNTE91i233OJ5ZuzYsTE9VjJ75513PM+8+OKLnmf+9Kc/eZ45ffq05xmgv/AKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwcVI+0lhYaHnmeXLl3uemT59uueZ6667zvNMsjt16lRMc6tWrfI885Of/MTzTEdHh+cZINXwCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHFSPvJ/Pnz+2WmP33wwQeeZ3bs2OF55qOPPvI88+KLL3qekaS2traY5gB4xysgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMCEzznnrDdxvnA4rEAgYL0NAMBlCoVCysjI6PN+XgEBAEwQIACACU8Bqqys1LRp05Senq6cnBzNmzdPdXV1UcfMnDlTPp8vai1evDiumwYADHyeAlRTU6OysjLt2bNHb775ps6ePavZs2ero6Mj6riHHnpIzc3NkbVy5cq4bhoAMPB5+o2oO3fujPp43bp1ysnJ0f79+zVjxozI7VdffbWCwWB8dggASEmX9TOgUCgkScrKyoq6/bXXXlN2drYmTZqkiooKnTp1qs/P0dXVpXA4HLUAAFcAF6Pu7m731a9+1d16661Rt69Zs8bt3LnTHTp0yP3ud79z1113nZs/f36fn2fFihVOEovFYrFSbIVCoYt2JOYALV682I0ZM8Y1NTVd9LiqqionydXX1/d6f2dnpwuFQpHV1NRkftJYLBaLdfnrUgHy9DOgj5WXl2vHjh3avXu3Ro4cedFjCwsLJUn19fUaN27cBff7/X75/f5YtgEAGMA8Bcg5p0cffVRbtmxRdXW1CgoKLjlz8OBBSVJeXl5MGwQApCZPASorK9OGDRu0bds2paenq6WlRZIUCAQ0bNgwHTlyRBs2bNBXvvIVjRgxQocOHdLSpUs1Y8YMTZ48OSH/AACAAcrLz33Ux/f51q5d65xzrrGx0c2YMcNlZWU5v9/vxo8f75YvX37J7wOeLxQKmX/fksVisViXvy71tZ+LkQIAEoKLkQIAkhIBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwETSBcg5Z70FAEAcXOrredIFqL293XoLAIA4uNTXc59LspccPT09OnbsmNLT0+Xz+aLuC4fDGjVqlJqampSRkWG0Q3uch3M4D+dwHs7hPJyTDOfBOaf29nbl5+dr0KC+X+cM6cc9fSqDBg3SyJEjL3pMRkbGFf0E+xjn4RzOwzmch3M4D+dYn4dAIHDJY5LuW3AAgCsDAQIAmBhQAfL7/VqxYoX8fr/1VkxxHs7hPJzDeTiH83DOQDoPSfcmBADAlWFAvQICAKQOAgQAMEGAAAAmCBAAwMSACdDq1at1/fXX66qrrlJhYaHeffdd6y31u2eeeUY+ny9qTZw40XpbCbd7927NnTtX+fn58vl82rp1a9T9zjk9/fTTysvL07Bhw1RcXKzDhw/bbDaBLnUeHnjggQueH3PmzLHZbIJUVlZq2rRpSk9PV05OjubNm6e6urqoYzo7O1VWVqYRI0bommuu0cKFC9Xa2mq048T4NOdh5syZFzwfFi9ebLTj3g2IAL3++utatmyZVqxYoffee09TpkxRSUmJjh8/br21fnfTTTepubk5sv7yl79YbynhOjo6NGXKFK1evbrX+1euXKlVq1bp1Vdf1d69ezV8+HCVlJSos7Ozn3eaWJc6D5I0Z86cqOfHxo0b+3GHiVdTU6OysjLt2bNHb775ps6ePavZs2ero6MjcszSpUu1fft2bd68WTU1NTp27JgWLFhguOv4+zTnQZIeeuihqOfDypUrjXbcBzcATJ8+3ZWVlUU+7u7udvn5+a6ystJwV/1vxYoVbsqUKdbbMCXJbdmyJfJxT0+PCwaD7oUXXojc1tbW5vx+v9u4caPBDvvHJ8+Dc84tWrTI3X333Sb7sXL8+HEnydXU1Djnzv27Hzp0qNu8eXPkmL///e9OkqutrbXaZsJ98jw459wdd9zhHnvsMbtNfQpJ/wrozJkz2r9/v4qLiyO3DRo0SMXFxaqtrTXcmY3Dhw8rPz9fY8eO1f3336/GxkbrLZlqaGhQS0tL1PMjEAiosLDwinx+VFdXKycnRxMmTNAjjzyiEydOWG8poUKhkCQpKytLkrR//36dPXs26vkwceJEjR49OqWfD588Dx977bXXlJ2drUmTJqmiokKnTp2y2F6fku5ipJ/04Ycfqru7W7m5uVG35+bm6h//+IfRrmwUFhZq3bp1mjBhgpqbm/Xss8/q9ttv1/vvv6/09HTr7ZloaWmRpF6fHx/fd6WYM2eOFixYoIKCAh05ckRPPvmkSktLVVtbq8GDB1tvL+56enq0ZMkS3XrrrZo0aZKkc8+HtLQ0ZWZmRh2bys+H3s6DJH3zm9/UmDFjlJ+fr0OHDun73/++6urq9Pvf/95wt9GSPkD4f6WlpZE/T548WYWFhRozZozeeOMNPfjgg4Y7QzK49957I3+++eabNXnyZI0bN07V1dWaNWuW4c4So6ysTO+///4V8XPQi+nrPDz88MORP998883Ky8vTrFmzdOTIEY0bN66/t9mrpP8WXHZ2tgYPHnzBu1haW1sVDAaNdpUcMjMzdeONN6q+vt56K2Y+fg7w/LjQ2LFjlZ2dnZLPj/Lycu3YsUNvv/121K9vCQaDOnPmjNra2qKOT9XnQ1/noTeFhYWSlFTPh6QPUFpamqZOnaqqqqrIbT09PaqqqlJRUZHhzuydPHlSR44cUV5envVWzBQUFCgYDEY9P8LhsPbu3XvFPz+OHj2qEydOpNTzwzmn8vJybdmyRbt27VJBQUHU/VOnTtXQoUOjng91dXVqbGxMqefDpc5Dbw4ePChJyfV8sH4XxKexadMm5/f73bp169wHH3zgHn74YZeZmelaWlqst9avvve977nq6mrX0NDg/vrXv7ri4mKXnZ3tjh8/br21hGpvb3cHDhxwBw4ccJLcSy+95A4cOOD+9a9/Oeece/75511mZqbbtm2bO3TokLv77rtdQUGBO336tPHO4+ti56G9vd09/vjjrra21jU0NLi33nrLff7zn3c33HCD6+zstN563DzyyCMuEAi46upq19zcHFmnTp2KHLN48WI3evRot2vXLrdv3z5XVFTkioqKDHcdf5c6D/X19e6HP/yh27dvn2toaHDbtm1zY8eOdTNmzDDeebQBESDnnPvFL37hRo8e7dLS0tz06dPdnj17rLfU7+655x6Xl5fn0tLS3HXXXefuueceV19fb72thHv77bedpAvWokWLnHPn3or91FNPudzcXOf3+92sWbNcXV2d7aYT4GLn4dSpU2727Nnu2muvdUOHDnVjxoxxDz30UMr9T1pv//yS3Nq1ayPHnD592n33u991n/nMZ9zVV1/t5s+f75qbm+02nQCXOg+NjY1uxowZLisry/n9fjd+/Hi3fPlyFwqFbDf+Cfw6BgCAiaT/GRAAIDURIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACb+Dwuo74MxItlsAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "plt.imshow(train_images[0], interpolation=\"nearest\",cmap=\"gray\")\n",
    "print(train_labels[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class neuralnet:\n",
    "\n",
    "    def __init__(self, numinputs, numoutputs, errorfunc=\"MSE\"):\n",
    "\n",
    "        self.numinputs = numinputs\n",
    "        self.numoutputs = numoutputs\n",
    "        self.errorfunc = errorfunc\n",
    "        \n",
    "        self.biases = np.random.default_rng().random(self.numoutputs)\n",
    "        self.weights = np.random.default_rng().random((self.numoutputs, self.numinputs))\n",
    "\n",
    "    def evaluate(self, inputs):\n",
    "            try:\n",
    "                output = self.weights @ inputs + self.biases\n",
    "                return output\n",
    "            except:\n",
    "                print(\"Dimension mismatch!\")\n",
    "\n",
    "    def computeerror(self, outputs, trueoutputs):\n",
    "         if self.errorfunc == \"MSE\":\n",
    "            pass\n",
    "         \n",
    "\n",
    "         if self.errorfunc == \"CrossEntropy\":\n",
    "            sum = 0\n",
    "            for i in range(0, len(outputs)):\n",
    "                sum += -trueoutputs[i]*math.log2(outputs[i])\n",
    "            return sum\n",
    "              \n",
    "\n",
    "         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([193.04718293, 193.27476388, 190.61200436, 198.62617653,\n",
       "       195.52217258, 201.13442827, 193.99978066, 198.67835004,\n",
       "       194.87877139, 204.54418108])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyNeuralNet = neuralnet(784,10)\n",
    "test1 = np.random.default_rng().random(784)\n",
    "\n",
    "MyNeuralNet.evaluate(test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73835717 0.09554734 0.23160377 0.48765978 0.39533229 0.49924819\n",
      " 0.71748722 0.43501056 0.36871492 0.0652077 ]\n"
     ]
    }
   ],
   "source": [
    "print(MyNeuralNet.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([12587.78949241, 14423.55803306, 12721.80081735, 13952.31824978,\n",
       "       13618.08646918, 14109.19782533, 13903.74661992, 14332.69599112,\n",
       "       13274.82260772, 14829.02715935])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(train_images[0])\n",
    "train1flat = train_images[0].flatten()\n",
    "print(len(train1flat))\n",
    "\n",
    "MyNeuralNet.evaluate(train1flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.09411765 0.44705882\n",
      " 0.86666667 0.99215686 0.99215686 0.99215686 0.99215686 0.78823529\n",
      " 0.30588235 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([49.97501473, 56.76272069, 50.42941251, 55.62817001, 54.28410539,\n",
       "       56.30054884, 55.19160726, 56.29922904, 52.5972755 , 58.25347608])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1converted = train_images[0].astype(float)/255\n",
    "print(train1converted[20])\n",
    "\n",
    "MyNeuralNet.evaluate(train1converted.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41672361 0.5136382  0.50385447 0.72451633 0.56789584 0.44384644\n",
      " 0.1984044  0.48524081 0.46961551 0.56155606 0.23530041 0.53424386\n",
      " 0.31946355 0.67302827 0.05035832 0.66516931 0.22149033 0.26328539\n",
      " 0.61875521 0.6725908  0.60475662 0.2490647  0.42544319 0.40754792\n",
      " 0.81327824 0.75980894 0.81878425 0.6120839  0.98412533 0.95728469\n",
      " 0.98843513 0.84835752 0.98912614 0.67864999 0.14434209 0.24402164\n",
      " 0.39165774 0.72150533 0.51620598 0.52694484 0.35272956 0.30794896\n",
      " 0.94394752 0.64650077 0.24700256 0.98830052 0.25528537 0.00965429\n",
      " 0.52754371 0.16922278 0.77315411 0.11458861 0.40949241 0.80950241\n",
      " 0.93233711 0.11741963 0.20431621 0.13415428 0.97012031 0.9703365\n",
      " 0.91498432 0.98277294 0.43922289 0.33301731 0.31519663 0.63344749\n",
      " 0.36617925 0.2076625  0.87751793 0.77797794 0.54432523 0.25567167\n",
      " 0.40475118 0.01278671 0.94560712 0.87163666 0.92737767 0.20944387\n",
      " 0.69381934 0.28970245 0.34222428 0.53541938 0.73472482 0.20486314\n",
      " 0.1936232  0.60604829 0.75341726 0.4787971  0.92574969 0.36865141\n",
      " 0.584613   0.00256134 0.7657287  0.3255245  0.2263953  0.29865421\n",
      " 0.56890726 0.00416564 0.52631736 0.1249001  0.24982005 0.55135953\n",
      " 0.33212892 0.2210184  0.42863481 0.39557497 0.6369817  0.89497013\n",
      " 0.78318752 0.63581026 0.98159299 0.84394675 0.05782762 0.47443144\n",
      " 0.17163356 0.1249046  0.15536789 0.27610042 0.78889928 0.21424508\n",
      " 0.73795873 0.77505347 0.68152779 0.27756401 0.65156071 0.75704515\n",
      " 0.21304317 0.31886834 0.39236412 0.49300797 0.69293822 0.83156843\n",
      " 0.23041876 0.00836001 0.14829042 0.44680748 0.53607632 0.34162771\n",
      " 0.72202716 0.82966154 0.39502417 0.12127456 0.13017444 0.50648711\n",
      " 0.03402906 0.57334594 0.39083365 0.77058883 0.29116227 0.66477268\n",
      " 0.07552454 0.20051639 0.89480466 0.61547787 0.8213793  0.71935198\n",
      " 0.47235943 0.41532259 0.43558049 0.87121734 0.80965458 0.36311811\n",
      " 0.67702084 0.71834213 0.79490645 0.11722622 0.28993601 0.97269662\n",
      " 0.09929092 0.49827353 0.16568333 0.97627074 0.51079593 0.69791922\n",
      " 0.57748551 0.84602236 0.82338994 0.6733921  0.29307014 0.9947598\n",
      " 0.54397361 0.29635818 0.02286013 0.32985158 0.95596437 0.01630206\n",
      " 0.25953936 0.14203394 0.44935811 0.24234997 0.57012891 0.18413741\n",
      " 0.44176214 0.51390428 0.65136327 0.75016277 0.90802163 0.84695493\n",
      " 0.29735417 0.86322321 0.55648607 0.90299555 0.10556539 0.00153531\n",
      " 0.53062309 0.9830146  0.77410871 0.83281152 0.97756094 0.33093062\n",
      " 0.05684212 0.58767356 0.42293885 0.56477048 0.73016412 0.18735172\n",
      " 0.11946259 0.78349866 0.89939052 0.4042934  0.51915337 0.75867326\n",
      " 0.49557159 0.90345629 0.60341638 0.89943826 0.08934756 0.9361231\n",
      " 0.35809125 0.84957624 0.54531365 0.96566861 0.34687171 0.04418946\n",
      " 0.55270045 0.41011583 0.88607029 0.24032375 0.45973408 0.59648634\n",
      " 0.8150111  0.02848842 0.0018977  0.86364454 0.81871782 0.08905735\n",
      " 0.45502403 0.39508997 0.74265218 0.88631303 0.57189669 0.48705084\n",
      " 0.43113607 0.26604529 0.28883477 0.92483392 0.54961679 0.90181449\n",
      " 0.40928367 0.56510539 0.09962388 0.812427   0.80041863 0.06301448\n",
      " 0.88910658 0.82373984 0.480299   0.92551277 0.25952078 0.87122011\n",
      " 0.7886707  0.31116053 0.09569021 0.87626057 0.96504222 0.48920046\n",
      " 0.90362551 0.66312658 0.88722972 0.88049573 0.08628341 0.11554225\n",
      " 0.65927349 0.03972402 0.51974064 0.71124628 0.82579261 0.13511168\n",
      " 0.11769478 0.71957039 0.43901894 0.18092844 0.21648252 0.36892549\n",
      " 0.7026594  0.27586152 0.91355189 0.85676312 0.3820161  0.63488208\n",
      " 0.94721334 0.59348003 0.49575202 0.55932124 0.17741757 0.0993347\n",
      " 0.90631491 0.15682139 0.82505223 0.80022049 0.84724521 0.07301602\n",
      " 0.53298617 0.23854631 0.31343506 0.11860793 0.43331541 0.41223496\n",
      " 0.65971402 0.0877617  0.06951129 0.79178835 0.90088202 0.70347607\n",
      " 0.11125409 0.31871126 0.81618634 0.53544351 0.31255245 0.30645734\n",
      " 0.42121167 0.58727858 0.00331112 0.10621604 0.14900346 0.31053047\n",
      " 0.0763333  0.72418217 0.53055168 0.47513486 0.91764838 0.33621862\n",
      " 0.35178521 0.93300778 0.11271201 0.89351364 0.39647602 0.36505846\n",
      " 0.45509715 0.28669983 0.21388473 0.05139704 0.52936881 0.05460833\n",
      " 0.4343402  0.62327392 0.6017817  0.50646464 0.49866282 0.12304283\n",
      " 0.49294051 0.4257309  0.27404507 0.13167495 0.77908736 0.34905212\n",
      " 0.93242774 0.03204496 0.51922581 0.06823035 0.17435797 0.51210955\n",
      " 0.34825528 0.2333812  0.50882133 0.0311168  0.46682809 0.71690417\n",
      " 0.02286653 0.00402652 0.53772195 0.56841138 0.1840957  0.14134991\n",
      " 0.3957321  0.76031576 0.71165321 0.18158317 0.54524552 0.10788007\n",
      " 0.14876123 0.43681473 0.15598765 0.59460604 0.25847002 0.99331517\n",
      " 0.48162917 0.25380777 0.52308912 0.57239675 0.88420495 0.34419226\n",
      " 0.72737601 0.91076184 0.49855679 0.15312692 0.43409511 0.06348612\n",
      " 0.69636604 0.51857502 0.63099224 0.27936934 0.60239816 0.29379364\n",
      " 0.25286175 0.20760671 0.51600011 0.84047148 0.26863608 0.69933954\n",
      " 0.13186729 0.00699349 0.42946985 0.52145567 0.81637351 0.4612648\n",
      " 0.41338398 0.51863254 0.0683351  0.16355735 0.12511021 0.90750791\n",
      " 0.74301928 0.57101561 0.77793899 0.99381483 0.28358358 0.27878097\n",
      " 0.70696032 0.33607336 0.37411702 0.97141963 0.68044676 0.55616785\n",
      " 0.51793927 0.13087597 0.05366967 0.57870424 0.3022511  0.54457792\n",
      " 0.94719321 0.82363385 0.50704218 0.11997506 0.32158371 0.9413319\n",
      " 0.99915244 0.01146399 0.92954848 0.36018463 0.22230695 0.37164545\n",
      " 0.82127129 0.05303141 0.62513938 0.45715223 0.44135888 0.05602705\n",
      " 0.47205147 0.03114426 0.78984285 0.65480792 0.54426574 0.20109082\n",
      " 0.2483067  0.45549345 0.05418457 0.99342049 0.99367207 0.29082075\n",
      " 0.71991158 0.4714021  0.83911405 0.89736276 0.42354054 0.52059788\n",
      " 0.05076251 0.14887527 0.47765223 0.8049356  0.45610656 0.69638761\n",
      " 0.11339597 0.43773607 0.92251457 0.06585967 0.05195685 0.15785521\n",
      " 0.49012194 0.50878398 0.05762843 0.1640363  0.99171754 0.88088032\n",
      " 0.93633792 0.04422514 0.41740066 0.07996531 0.03813046 0.35555038\n",
      " 0.19946238 0.03435437 0.34518166 0.670173   0.17290535 0.46617622\n",
      " 0.64347736 0.39487937 0.60141716 0.52619031 0.25534983 0.45024779\n",
      " 0.16481986 0.22231338 0.26067487 0.04522002 0.02955002 0.44236378\n",
      " 0.90881914 0.54450374 0.56017923 0.31304666 0.85297016 0.45453805\n",
      " 0.30869116 0.49808515 0.72580199 0.74692011 0.44690747 0.47534928\n",
      " 0.13987112 0.86173462 0.70385662 0.09326881 0.5056847  0.02317069\n",
      " 0.27929168 0.26561123 0.44807298 0.92434978 0.81571752 0.04494413\n",
      " 0.63592516 0.20168608 0.18904535 0.74173084 0.82845003 0.1468645\n",
      " 0.55927564 0.75103482 0.6882946  0.23620135 0.06573951 0.56991336\n",
      " 0.8162309  0.73925179 0.26461774 0.16564716 0.53588927 0.48442004\n",
      " 0.35377789 0.53089833 0.47210988 0.80641957 0.72567508 0.65494928\n",
      " 0.09187036 0.91533786 0.8182696  0.4473728  0.24095294 0.77038902\n",
      " 0.6867822  0.88933693 0.23454794 0.22658857 0.94413235 0.47569673\n",
      " 0.80271846 0.41850023 0.23078088 0.29810133 0.57348004 0.77403283\n",
      " 0.25603742 0.40826731 0.60951508 0.08576798 0.47037316 0.50714478\n",
      " 0.80459608 0.21108924 0.61556688 0.04473552 0.47412329 0.59285778\n",
      " 0.83512235 0.87721183 0.07248642 0.52676432 0.0788783  0.65309161\n",
      " 0.85864123 0.99788782 0.45227108 0.31820559 0.83228987 0.00170146\n",
      " 0.47152891 0.85043755 0.62970054 0.14417216 0.20970193 0.17733295\n",
      " 0.16395281 0.16246847 0.83651808 0.30617103 0.12483547 0.4538864\n",
      " 0.46924992 0.44825895 0.09105258 0.733122   0.63402256 0.65027359\n",
      " 0.3734062  0.62788286 0.85752893 0.57209458 0.75747131 0.78887371\n",
      " 0.26008036 0.14109104 0.93516332 0.26078788 0.45325466 0.97580129\n",
      " 0.4720094  0.37150605 0.6445518  0.9659323  0.58437748 0.97044924\n",
      " 0.27565517 0.28073639 0.16610501 0.92291567 0.46519905 0.44629124\n",
      " 0.05898263 0.38372894 0.81311889 0.02993309 0.65208004 0.04084894\n",
      " 0.51724377 0.38580225 0.7124949  0.87954078 0.75737659 0.36033435\n",
      " 0.27826996 0.71442691 0.4299869  0.34869916 0.73622013 0.11291242\n",
      " 0.59502593 0.87169234 0.0210581  0.17053926 0.37982048 0.38632642\n",
      " 0.75105414 0.04599327 0.98701619 0.4025448  0.30078524 0.33446424\n",
      " 0.78076978 0.01557063 0.49784399 0.82353438 0.68417685 0.4468618\n",
      " 0.36682185 0.89859714 0.94687127 0.0127709  0.78776996 0.51407795\n",
      " 0.19769601 0.90191301 0.62113215 0.31672366 0.5454876  0.86848259\n",
      " 0.03445858 0.49487175 0.60752527 0.91978228 0.6159701  0.12884759\n",
      " 0.96644313 0.91996365 0.39234038 0.55176134 0.55012107 0.51109462\n",
      " 0.88877112 0.18560361 0.79620095 0.97172072 0.90495818 0.02880026\n",
      " 0.59139291 0.20005477 0.6906762  0.06767776 0.72136714 0.71606383\n",
      " 0.56549246 0.56869397 0.63109442 0.36715095 0.49254782 0.85066072\n",
      " 0.23202746 0.15492465 0.85542196 0.23053091 0.20683249 0.5346708\n",
      " 0.77683686 0.58653906 0.27176422 0.23205483 0.36374574 0.88826556\n",
      " 0.04851008 0.91596291 0.27836279 0.94938795 0.17826581 0.29602351\n",
      " 0.50792128 0.75363684 0.08228416 0.02706756 0.14495837 0.16006331\n",
      " 0.87974395 0.10108297 0.92801501 0.13664867 0.31497328 0.5229371\n",
      " 0.42461571 0.63818334 0.25247965 0.67491577 0.43993306 0.16410034\n",
      " 0.39020506 0.18478219 0.95925667 0.06316474 0.2583982  0.44690941\n",
      " 0.10198025 0.71746688 0.369002   0.68763612]\n"
     ]
    }
   ],
   "source": [
    "print(MyNeuralNet.weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
